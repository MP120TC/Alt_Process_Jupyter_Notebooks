{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b6aa48",
   "metadata": {},
   "source": [
    "# Linearize Datacolor .txt Files\n",
    "This notebook will read Datacolor .txt files generated from reading a test chart, determine the resulting curve, and generate a smoothed linearization curve.\n",
    "\n",
    "### Prior to Running Any Test Charts\n",
    "1. Make a spectro calibration print.  Expose a piece of coated paper.  Cover up half of it with something completely opaque.  The other half should be covered with a blank piece of transparency.\n",
    "1. Read the dark areas and find the darkest value you can.  Write it down - you'll be entering this number below as the **calib_darkest**.\n",
    "1. Read the coated but unexposed areas and find the lightest value you can.  Write it down - you'll be entering this number below as the **calib_brightest**\n",
    "\n",
    "You only need to do this step one time per process type.  After you enter these values, save the notebook so you can re-use these values for every subsequent test for that process type.  You may want to write the values you read on the paper itself in case you change this notebook for another type of process.\n",
    "\n",
    "### Datacolor .txt Files\n",
    "This notebook processes the .txt files generated by Spyder Print's Measurement function.  These files are merely space-delimited L\\*a\\*b files, where each line is one measurement and the L, a, and b values are separated by space characters.  The measurements should be in order in the file from the lightest patch to the darkest patch.\n",
    "\n",
    "**WHEN READING YOUR TEST CHARTS, READ FROM THE LIGHT PATCHES TO THE DARK PATCHES, IN ORDER!**\n",
    "\n",
    "Note that if you are using a spectrocolorimeter other than a Datacolor device, you can still produce this file, providing you can get L\\*a\\*b values out of it.  The formatting of the .txt file must conform to the description above, but the notebook doesn't care what device produced the values.\n",
    "\n",
    "### Preparing Test Chart Negatives\n",
    "When making your negative, **ensure that you add a patch of pure black** after you have inverted the chart image.  This patch must be as black as your printer can produce, so the paper under it is coated, but completely unexposed.  You will be reading this resulting patch as your lightest reading to make sure the values in the .txt file can be normalized to correspond to other tests.  Basically you are determining the lightest possible value your coated paper can produce.\n",
    "\n",
    "### Reading the Test Charts\n",
    "1. Read the test chart in Spyder Print's Measurement function.  Do this at least 3 times, producing 3 separate .txt files. If you want, you can do this more times for a better average per patch.  For each patch, the values for all of these files will be averaged to minimize noise and inconsistencies. \n",
    "1. Read the white patch you added to your negative.  This needs to be coated, but un-exposed.  Write this number down - you'll be entering it when prompted.\n",
    "1. Read the darkest part of your print, preferably in a location where the film covered the paper, but had no ink density.  Write this number down - you'll be entering it when prompted.\n",
    "\n",
    "### How To Use This Notebook\n",
    "The code in this notebook is organized into cells.  Each cell can be run independently, providing all prerequisite imports have been done and all variables exist.  However, **it is recommended that you run all code cells in sequence.** \n",
    "\n",
    "**IMPORTANT:** As mentioned above, you will need to provide 4 values in the [Enter the calibration and test chart brightest and darkest values](#Enter-the-calibration-and-test-chart-brightest-and-darkest-values) cell.  **Do not forget to do this!**\n",
    "\n",
    "The exceptions to this normal operation are that you may wish to run the [Mirror and Smooth](#Mirror-and-Smooth) cell more than once, providing different smoothing values until you are satisfied with the results.  Once you are happy with the resulting curve, you can then move on to the [Save the New Curve to a .cube File](#Save-the-New-Curve-to-a-.cube-File) cell to save the new .cube file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39048eed",
   "metadata": {},
   "source": [
    "# Enter the calibration and test chart brightest and darkest values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb5ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following are values from the spectro calibration test print\n",
    "calib_brightest = 96.5\n",
    "calib_darkest = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427516c8",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7572f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate\n",
    "from tkinter import Tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import simpledialog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d84de",
   "metadata": {},
   "source": [
    "# Get the paths to the .txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "root.wm_attributes('-topmost', 1)\n",
    "root.withdraw()\n",
    "txt_files = filedialog.askopenfilenames(title=\"Datacolor Measurement .txt file(s)\", filetypes=[(\"TXT files\", \"*.txt\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8405f5f3",
   "metadata": {},
   "source": [
    "# Read the .txt files and average the values per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for txt in txt_files:\n",
    "    df = pd.read_csv(txt, header=None, usecols=[0], sep='\\t')\n",
    "    dfs.append(df)\n",
    "# rename the columns in each dataframe\n",
    "for i in range(len(dfs)):\n",
    "    dfs[i].rename(columns={0:\"Text_File_{}\".format(i+1)}, inplace=True)\n",
    "# make the value steps\n",
    "value_steps = []\n",
    "num_steps = len(dfs[0].index)\n",
    "step_increment = 1.0 / (num_steps - 1)\n",
    "min_val = 0\n",
    "for i in range(num_steps):\n",
    "    value_steps.append(round(min_val + (i * step_increment), 4) * 100)\n",
    "# check to see if the value steps' order matches the first dataframe\n",
    "mindf = dfs[0][['Text_File_1']].idxmin().values[0]\n",
    "maxdf = dfs[0][['Text_File_1']].idxmax().values[0]\n",
    "# create a dataframe using the value steps as the index\n",
    "datacolor_df = pd.DataFrame({\"Linear\":value_steps}, index=value_steps)\n",
    "# add the values from the TXT dataframes\n",
    "column_names = []\n",
    "for i in range(len(dfs)):\n",
    "    col_vals = dfs[i]['Text_File_{}'.format(i+1)].tolist()\n",
    "    # make sure the list values are increasing, not decreasing\n",
    "    if col_vals[0] > col_vals[-1]:\n",
    "        col_vals.reverse()\n",
    "    datacolor_df['Text_File_{}'.format(i+1)] = col_vals\n",
    "    column_names.append('Text_File_{}'.format(i+1))\n",
    "# average the text file columns\n",
    "datacolor_df[\"Avg_TXT_values\"] = datacolor_df[column_names].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb85916",
   "metadata": {},
   "source": [
    "# Inspect the values\n",
    "The cell below prints out all of the values so you can inspect them.  If you don't care to see them, you can skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7741d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacolor_df.head(num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(xval, df, xcol, ycol):\n",
    "    \"\"\"\n",
    "    This function returns an interpolated value from a dataframe at a specified X value.\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    xval: numeric - the X value at which you wish to get the interpolated Y value\n",
    "    df: pandas dataframe - the dataframe containing the data to be interpolated\n",
    "    xcol: string - the name of the column in the dataframe containing X values\n",
    "    ycol: string - the name of the column in the dataframe containing Y values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (interpolated_value, X, Y)\n",
    "    \"\"\"\n",
    "    return np.interp([xval], df[xcol], df[ycol])\n",
    "\n",
    "\n",
    "def perpendicular_dist_from_linear(pt_x, pt_y):\n",
    "    linear_x = (pt_x + pt_y) / 2.0\n",
    "    dist_from_linear = math.dist([linear_x, linear_x], [pt_x, pt_y])\n",
    "    if pt_y < linear_x:\n",
    "        dist_from_linear = -1.0 * dist_from_linear\n",
    "    return [linear_x, dist_from_linear]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b380c",
   "metadata": {},
   "source": [
    "# Normalize the data so it falls within the calibrated range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c9c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightest_reading = simpledialog.askfloat(title=\"Lightest Measured Value\", prompt=\"Enter the value of the coated but unexposed patch you read from your test.\", initialvalue=calib_brightest)\n",
    "darkest_reading = simpledialog.askfloat(title=\"Darkest Measured Value\", prompt=\"Enter the value from fully exposed coated paper.\", initialvalue=calib_darkest)\n",
    "# Normalize - scale the values to fit within the calibrated values\n",
    "dark_correct = calib_darkest - darkest_reading\n",
    "new_lightest = lightest_reading + dark_correct\n",
    "light_scaling = 100 / new_lightest\n",
    "datacolor_df['Avg_TXT_values'] = (datacolor_df['Avg_TXT_values'] + dark_correct)\n",
    "datacolor_df['Avg_TXT_values'] = (datacolor_df['Avg_TXT_values'] * light_scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4149a8c1",
   "metadata": {},
   "source": [
    "# Mirror and Smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979616d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mirror the values around the diagonal\n",
    "perp_dists = {}\n",
    "for i, row in datacolor_df.iterrows():\n",
    "    the_x, the_dist = perpendicular_dist_from_linear(row['Linear'], row['Avg_TXT_values'])\n",
    "    perp_dists[the_x] = the_dist\n",
    "perp_vals = []\n",
    "new_y_vals = []\n",
    "for line_val in perp_dists.keys():\n",
    "    dist_val = perp_dists[line_val]\n",
    "    dist_sqrt = abs(dist_val) / math.sqrt(2.0)\n",
    "    if dist_val < 0:\n",
    "        perp_vals.append(line_val - dist_sqrt)\n",
    "        new_y_vals.append(line_val + dist_sqrt)\n",
    "    else:\n",
    "        perp_vals.append(line_val + dist_sqrt)\n",
    "        new_y_vals.append(line_val - dist_sqrt)\n",
    "mirror_df = pd.DataFrame({\"Line_Vals\":perp_vals, \"Mirror_Values\": new_y_vals}, index=perp_vals)\n",
    "# interpolate the data so it can be added to the original dataframe\n",
    "new_curve_vals = []\n",
    "for i in value_steps:\n",
    "    ival = interpolate(i, mirror_df,'Line_Vals', 'Mirror_Values')\n",
    "    new_curve_vals.append(ival[0])\n",
    "datacolor_df['Mirrored_TXT_Values'] = new_curve_vals\n",
    "# smooth the mirrored values\n",
    "smoothing_factor_value = simpledialog.askinteger(title=\"Smoothing Factor\", prompt=\"Enter a smoothing factor.\\nBigger numbers mean a smoother result.\\nValues between 20 and 150 are most common.\", initialvalue=50)\n",
    "if smoothing_factor_value == None:\n",
    "    smoothing_factor_value = 50\n",
    "avg_spline = scipy.interpolate.UnivariateSpline(datacolor_df['Linear'], datacolor_df['Mirrored_TXT_Values'], k=5)\n",
    "avg_spline.set_smoothing_factor(smoothing_factor_value)\n",
    "# get the smoothed readings, and make sure they're strictly increasing\n",
    "smoothed_vals = avg_spline(datacolor_df['Linear']).tolist()\n",
    "output_vals = []\n",
    "previous_val = -1\n",
    "for val in smoothed_vals:\n",
    "    if val > previous_val:\n",
    "        output_vals.append(val)\n",
    "        previous_val = val\n",
    "    else:\n",
    "        output_vals.append(previous_val)\n",
    "# add the values to the dataframe\n",
    "datacolor_df['Linearized_Curve'] = output_vals\n",
    "\n",
    "datacolor_df[['Linear','Avg_TXT_values', 'Mirrored_TXT_Values','Linearized_Curve']].plot(figsize=(7,7), grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a1c6a",
   "metadata": {},
   "source": [
    "# Save the New Curve to a .cube File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a03bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the curve so it falls within 0.0 and 1.0\n",
    "converted_vals = [e/100.0 for e in datacolor_df['Linearized_Curve'].tolist()]\n",
    "\n",
    "# get the output filename\n",
    "cube_filename = simpledialog.askstring(\"Output .cube File Name\", \"Enter the name for the output .cube file (no .cube extension)\")\n",
    "cube_filename = cube_filename.replace(\" \", \"_\")\n",
    "\n",
    "# save the new curve to a .cube file\n",
    "out_cube = os.path.join(os.path.dirname(txt_files[0]), \"{}.cube\".format(cube_filename))\n",
    "with open(out_cube, 'w') as cube:\n",
    "    cube.write(\"#Created by: Datacolor_Linearize Notebook\\nTITLE  \\\"{}\\\"\\nLUT_1D_SIZE {}\\nDOMAIN_MIN 0.0 0.0 0.0\\nDOMAIN_MAX 1.0 1.0 1.0\\n#LUT data points\\n\".format(cube_filename, len(converted_vals)))\n",
    "    line_template = \"{:<08} {:<08} {:<08}\\n\"\n",
    "    for row in converted_vals:\n",
    "        if row < 0.0:\n",
    "            val = 0.0\n",
    "        elif row > 1.0:\n",
    "            val = 1.0\n",
    "        else:\n",
    "            val = round(row, 6)\n",
    "        cube.write(line_template.format(val, val, val))\n",
    "    cube.write(\"#END data\\n\")\n",
    "print(\"Saved {}\".format(out_cube))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e94584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
